{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i0.wp.com/developer.ibm.com/messaging/wp-content/uploads/sites/18/2015/08/MessageHubBanner1.png?resize=562%2C229&ssl=1\" alt=\"Drawing\" style=\"width: 470px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Receive message events from IBM Message Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this python notebook, you will learn how to simulate streams by pushing sample messages to Message Hub which is currently based on Kafka 0.10.0.1. You will also consume these messages to perform analytics.\n",
    "\n",
    "Message Hub is a cloud-based platform as a service technology predestined for streaming batch and real-time data to run analytics applications. Thereby you are able to gain valuable insights into your data. We will use the [Kafka Rest API](https://console.ng.bluemix.net/docs/services/MessageHub/messagehub025.html#messagehub025 \"Documentation\") which is designed to provide a quick start for beginners. Once you are finished you are ready to use the main [Kafka API](https://console.ng.bluemix.net/docs/services/MessageHub/messagehub050.html#messagehub050 \"Documentation\") which is used for high throughout use cases. Especially in the era of the Internet of Things there will be many application scenarios. So let's get started. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Message Hub acts like a real-time messaging system or data pipeline used for all incoming and outgoing communication. The most important terms are\n",
    "\n",
    "- Topic\n",
    "- Producer\n",
    "- Consumer\n",
    "- Cluster \n",
    "\n",
    "A producer sends a message to a specific topic within a Kafka cluster and a consumer receives this message by subscribing to this topic. \n",
    "\n",
    "A message can be addressed to a specific consumer group. The message is sent only to one consumer instance. The benefit is that the process of sending a message from end to end can be done in a shorter period of time. After the message is sent, the consumer instance shares the received message with the whole group. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<CENTER><img src=\"http://kafka.apache.org/090/images/producer_consumer.png\n",
    "\" alt=\"Drawing\" style=\"width: 275px;\"/></CENTER>\n",
    "\n",
    "(Img.1:  Basic architecture, [Kafka Documentation](http://kafka.apache.org/090/documentation.html \"Documentation\"))<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will create your own Message Hub instance and perform some prerequisites. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: requests in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s0d3-ac5d8d40b1dea6-f436cf316f63/.local/lib/python3.5/site-packages\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s get started. To test Message Hub no credit card is needed. If you have registered your account with a credit card <b>be aware</b> that costs can occur. \n",
    "\n",
    "1. Please navigate to [Bluemix](http://bluemix.net/ \"Bluemix\"). \n",
    "2. Login and click on catalog. \n",
    "3. Search for “Message Hub” in the Application Services section.\n",
    "4. Create an instance \n",
    "5. In the \"Manage\" section create a topic name. The name will be needed later. \n",
    "6. Copy the Service Credentials without its {braces} and paste them into the next code snippet. \n",
    "7. Do not hesitate to use all code snippets in this blog as desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "credentials ={\n",
    " \"instance_id\": \"xxx\",\n",
    "  \"mqlight_lookup_url\": \"https://mqlight-lookup-prod01.messagehub.services.us-south.bluemix.net/Lookup?serviceId=xxx\",\n",
    "  \"api_key\": \"xxx\",\n",
    "  \"kafka_admin_url\": \"https://kafka-admin-prod01.messagehub.services.us-south.bluemix.net:443\",\n",
    "  \"kafka_rest_url\": \"https://kafka-rest-prod01.messagehub.services.us-south.bluemix.net:443\",\n",
    "  \"kafka_brokers_sasl\": [\n",
    "    \"kafka03-prod01.messagehub.services.us-south.bluemix.net:9093\",\n",
    "    \"kafka04-prod01.messagehub.services.us-south.bluemix.net:9093\",\n",
    "    \"kafka05-prod01.messagehub.services.us-south.bluemix.net:9093\",\n",
    "    \"kafka01-prod01.messagehub.services.us-south.bluemix.net:9093\",\n",
    "    \"kafka02-prod01.messagehub.services.us-south.bluemix.net:9093\"\n",
    "  ],\n",
    "  \"user\": \"xxx\",\n",
    "  \"password\": \"xxx\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create a Kafka consumer group and consumer instance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core of this sample notebook are the get and post requests. There are four parts of our HTTP requests we are sending.\n",
    "\n",
    " - Method (Get and Post)\n",
    " - Url (defines the source of the destination)\n",
    " - Header (Needed for authentication)\n",
    " - Body (contains the data we want to submit)\n",
    "\n",
    "A consumer group can contain one or more consumer instances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kafkaTopic = 'json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "consumerInstance = 'instance1'\n",
    "consumerGroup = 'group1'\n",
    "\n",
    "authToken = credentials['api_key']\n",
    "kafkaRestUrl = credentials['kafka_rest_url']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The header has to be defined one time only and will be used for all upcoming requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "headers = {\n",
    "    'X-Auth-Token': authToken,\n",
    "    'Content-Type': 'application/vnd.kafka.v1+json'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The consumer instance will be sent within the body. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "body1 = json.dumps({\n",
    "    'name': consumerInstance,\n",
    "    'format': 'binary',\n",
    "    'auto.offset.reset': 'smallest'\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following method sends a post request including both the authentication and consumer group details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setConsumerInstanceAndGroup(consumerGroup, body1, headers):\n",
    "    \n",
    "    response = requests.post(kafkaRestUrl + \"/consumers/\" + consumerGroup, data=body1, headers=headers)\n",
    "\n",
    "    print(response.status_code, response.reason, response.text)\n",
    "    result = response.json()\n",
    "    print(result)\n",
    "    consumerUrl = result['base_uri']\n",
    "    print(consumerUrl)\n",
    " \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method has to be executed one time only. <b>Existing consumer group/instance combinations will cause a 409 conflict</b>. Change the group or instance name in that case and repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 OK {\"instance_id\":\"instance1\",\"base_uri\":\"https://kafka-rest-prod01.messagehub.services.us-south.bluemix.net/consumers/group1/instances/instance1\"}\n",
      "{'base_uri': 'https://kafka-rest-prod01.messagehub.services.us-south.bluemix.net/consumers/group1/instances/instance1', 'instance_id': 'instance1'}\n",
      "https://kafka-rest-prod01.messagehub.services.us-south.bluemix.net/consumers/group1/instances/instance1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setConsumerInstanceAndGroup(consumerGroup, body1, headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Push a message event to Kafka "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can set the name of the topic. The name must be the same you have created manually in your Message Hub instance before. The first letter of the topic name should be in upper case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = kafkaRestUrl + \"/topics/\" + kafkaTopic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can set some messages. Edit the message and execute the method more often to produce more events.\n",
    "\n",
    "_Note: The values submitted in the records array have to be binary encoded for our consumer instance. JSON or Avro encoding is not currently supported with Message Hub REST API.\n",
    "To encode the value as binary, they have to be kept in byte arrays (not strings) and be decoded from the receiver into String values. _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"records\": [{\"value\": \"4d65726375727920\"}, {\"value\": \"56656e7573202020\"}, {\"value\": \"4561727468202020\"}, {\"value\": \"4d61727320202020\"}, {\"value\": \"4a75706974657220\"}, {\"value\": \"53617475726e2020\"}, {\"value\": \"5572616e75732020\"}, {\"value\": \"4e657074756e6520\"}]}'\n"
     ]
    }
   ],
   "source": [
    "import binascii\n",
    "\n",
    "body2 = json.dumps({\n",
    "    'records': [\n",
    "            {'value': binascii.hexlify(b\"Mercury \").decode('utf-8')},\n",
    "            {'value': binascii.hexlify(b\"Venus   \").decode('utf-8')},\n",
    "            {'value': binascii.hexlify(b\"Earth   \").decode('utf-8')},\n",
    "            {'value': binascii.hexlify(b\"Mars    \").decode('utf-8')},\n",
    "            {'value': binascii.hexlify(b\"Jupiter \").decode('utf-8')},\n",
    "            {'value': binascii.hexlify(b\"Saturn  \").decode('utf-8')},\n",
    "            {'value': binascii.hexlify(b\"Uranus  \").decode('utf-8')},\n",
    "            {'value': binascii.hexlify(b\"Neptune \").decode('utf-8')}\n",
    "        ]\n",
    "    }, ensure_ascii=False).encode('utf8')\n",
    "\n",
    "print(body2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pushMessageToKafka(kafkaTopic, url, body2, headers):\n",
    "    \n",
    "    response = requests.post(url, data=body2, headers=headers)\n",
    "    print(body2)\n",
    "     \n",
    "    print(response.status_code, response.reason, response.text)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To send this message, execute this method one or more times. Feel free to go back and <b>change the text of the message and execute this method again</b> to simulate a data stream. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"records\": [{\"value\": \"4d65726375727920\"}, {\"value\": \"56656e7573202020\"}, {\"value\": \"4561727468202020\"}, {\"value\": \"4d61727320202020\"}, {\"value\": \"4a75706974657220\"}, {\"value\": \"53617475726e2020\"}, {\"value\": \"5572616e75732020\"}, {\"value\": \"4e657074756e6520\"}]}'\n",
      "200 OK {\"offsets\":[{\"partition\":0,\"offset\":137,\"error_code\":null,\"error\":null},{\"partition\":0,\"offset\":138,\"error_code\":null,\"error\":null},{\"partition\":0,\"offset\":139,\"error_code\":null,\"error\":null},{\"partition\":0,\"offset\":140,\"error_code\":null,\"error\":null},{\"partition\":0,\"offset\":141,\"error_code\":null,\"error\":null},{\"partition\":0,\"offset\":142,\"error_code\":null,\"error\":null},{\"partition\":0,\"offset\":143,\"error_code\":null,\"error\":null},{\"partition\":0,\"offset\":144,\"error_code\":null,\"error\":null}],\"key_schema_id\":null,\"value_schema_id\":null}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pushMessageToKafka(kafkaTopic, url, body2, headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each time, the message is assigned to a partition uniquely identified by an ID called <b>offset</b>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<CENTER><img src=\"https://kafka.apache.org/0102/images/log_consumer.png\" alt=\"Drawing\" style=\"width: 400px;\"/></CENTER>\n",
    "Source: Sample partition https://kafka.apache.org/documentation/#introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Receive a message event from Kafka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loop below will run for some amount of time but we have to eventually stop it to process the results. What we have here is not an actual streaming receiver as needed for Spark Streaming. We only demonstrate Spark core functionality here by getting messages from Message Hub loaded into a Dataframe. \n",
    "\n",
    "Now it’s time to receive our messages by defining the following Method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import time\n",
    "import base64\n",
    "\n",
    "def getMessageFromKafka(maxArrayLength, maxIterations, consumerUrl, headers):\n",
    "    results = []\n",
    "    length = 0\n",
    "    iteration = 0\n",
    "    while (length < maxArrayLength):\n",
    "        if (iteration > maxIterations): break\n",
    "        \n",
    "        response = requests.get(kafkaRestUrl + \"/consumers/\"+consumerGroup+\"/instances/\"+consumerInstance+\"/topics/\"+kafkaTopic, headers=headers)        \n",
    "        print (response, response.reason, response.text)\n",
    "\n",
    "        data = response.text\n",
    "\n",
    "        x = json.loads(data)\n",
    "        length = length + len(x)\n",
    "        iteration = iteration + 1\n",
    "        \n",
    "        print ('===============================')\n",
    "        print ('Number of incoming messages: ', len(x))\n",
    "        print ('===============================')\n",
    "        \n",
    "        for obj in x:\n",
    "            value = binascii.unhexlify(obj['value']).decode('utf-8')\n",
    "        \n",
    "            print(value)\n",
    "            results.append(value)\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally execute the following method to receive all sent message events. Other parameters are set to limit the length of the message array and the number of iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]> OK [{\"key\":null,\"value\":\"4d65726375727920\",\"partition\":0,\"offset\":137},{\"key\":null,\"value\":\"56656e7573202020\",\"partition\":0,\"offset\":138},{\"key\":null,\"value\":\"4561727468202020\",\"partition\":0,\"offset\":139},{\"key\":null,\"value\":\"4d61727320202020\",\"partition\":0,\"offset\":140},{\"key\":null,\"value\":\"4a75706974657220\",\"partition\":0,\"offset\":141},{\"key\":null,\"value\":\"53617475726e2020\",\"partition\":0,\"offset\":142},{\"key\":null,\"value\":\"5572616e75732020\",\"partition\":0,\"offset\":143},{\"key\":null,\"value\":\"4e657074756e6520\",\"partition\":0,\"offset\":144}]\n",
      "===============================\n",
      "Number of incoming messages:  8\n",
      "===============================\n",
      "Mercury \n",
      "Venus   \n",
      "Earth   \n",
      "Mars    \n",
      "Jupiter \n",
      "Saturn  \n",
      "Uranus  \n",
      "Neptune \n",
      "<Response [200]> OK []\n",
      "===============================\n",
      "Number of incoming messages:  0\n",
      "===============================\n"
     ]
    }
   ],
   "source": [
    "maxArrayLength = 2000\n",
    "maxIterations = 1\n",
    "\n",
    "headers2 = {\n",
    "    'X-Auth-Token': authToken,\n",
    "    'Accept': 'application/vnd.binary.v1+json'\n",
    "}\n",
    "\n",
    "results = getMessageFromKafka (maxArrayLength, maxIterations, url, headers2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reading of the data starts from partition 0 beginning with the lowest ID (offset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Delete the Kafka consumer instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will drop the consumer instance so we avoid the 409 conflicts the next time we try to create an instance with the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deleteConsumerInstance(consumerGroup, consumerInstance, headers):\n",
    "    \n",
    "    response = requests.delete(kafkaRestUrl + \"/consumers/\" + consumerGroup + \"/instances/\" + consumerInstance,\n",
    "                               headers=headers)\n",
    "\n",
    "    print(response.status_code, response.reason, response.text)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected response from this call is a 204 (No Content) message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204 No Content \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [204]>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deleteConsumerInstance(consumerGroup, consumerInstance, headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Perform analytics to gain insights "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we received the data we are free to choose what we want to do with it. In this case we will create a simple tag cloud in Brunel. The message of the event is extracted and stored in the following list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mercury ',\n",
       " 'Venus   ',\n",
       " 'Earth   ',\n",
       " 'Mars    ',\n",
       " 'Jupiter ',\n",
       " 'Saturn  ',\n",
       " 'Uranus  ',\n",
       " 'Neptune ']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we transform the result into a Pandas dataframe. All we want is to construct a generic dataframe so we can inspect the data we got from the topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If index 0 is empty please execute the method again until the first index contains a word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mercury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Venus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jupiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Saturn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Uranus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Neptune</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Message\n",
       "0  Mercury \n",
       "1  Venus   \n",
       "2  Earth   \n",
       "3  Mars    \n",
       "4  Jupiter \n",
       "5  Saturn  \n",
       "6  Uranus  \n",
       "7  Neptune "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_pd = pd.DataFrame(results, columns=[\"Message\"])\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "results_pd.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating a pandas dataframe we can do everything supported in Spark, including Machine Learning, Visualization, Graphing, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_pd.to_csv('results_pd',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!--\n",
       "  ~ Copyright (c) 2015 IBM Corporation and others.\n",
       "  ~\n",
       "  ~ Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "  ~ You may not use this file except in compliance with the License.\n",
       "  ~ You may obtain a copy of the License at\n",
       "  ~\n",
       "  ~     http://www.apache.org/licenses/LICENSE-2.0\n",
       "  ~\n",
       "  ~ Unless required by applicable law or agreed to in writing, software\n",
       "  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "  ~ See the License for the specific language governing permissions and\n",
       "  ~ limitations under the License.\n",
       "  -->\n",
       "\n",
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"/data/jupyter2/7106bd0a-f68e-461a-a0d3-ac5d8d40b1de/nbextensions/brunel_ext/brunel.2.3.css\">\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"/data/jupyter2/7106bd0a-f68e-461a-a0d3-ac5d8d40b1de/nbextensions/brunel_ext/sumoselect.css\">\n",
       "\n",
       "<style>\n",
       "    \n",
       "</style>\n",
       "\n",
       "<div id=\"controlsid7722f66c-370b-11e7-bcfb-002590fb6e1c\" class=\"brunel\"/>\n",
       "<svg id=\"visid7722f3ba-370b-11e7-bcfb-002590fb6e1c\" width=\"700\" height=\"400\"></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "/*\n",
       " * Copyright (c) 2015 IBM Corporation and others.\n",
       " *\n",
       " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       " * You may not use this file except in compliance with the License.\n",
       " * You may obtain a copy of the License at\n",
       " *\n",
       " *     http://www.apache.org/licenses/LICENSE-2.0\n",
       " *\n",
       " * Unless required by applicable law or agreed to in writing, software\n",
       " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       " * See the License for the specific language governing permissions and\n",
       " * limitations under the License.\n",
       " */\n",
       "\n",
       "require.config({\n",
       "    waitSeconds: 60,\n",
       "    paths: {\n",
       "        'd3': '//cdnjs.cloudflare.com/ajax/libs/d3/4.2.1/d3.min',\n",
       "        'topojson': '//cdnjs.cloudflare.com/ajax/libs/topojson/1.6.20/topojson.min',\n",
       "        'brunel' : '/data/jupyter2/7106bd0a-f68e-461a-a0d3-ac5d8d40b1de/nbextensions/brunel_ext/brunel.2.3.min',\n",
       "        'brunelControls' : '/data/jupyter2/7106bd0a-f68e-461a-a0d3-ac5d8d40b1de/nbextensions/brunel_ext/brunel.controls.2.3.min'\n",
       "    },\n",
       "    shim: {\n",
       "       'brunel' : {\n",
       "            exports: 'BrunelD3',\n",
       "            deps: ['d3', 'topojson'],\n",
       "            init: function() {\n",
       "               return {\n",
       "                 BrunelD3 : BrunelD3,\n",
       "                 BrunelData : BrunelData\n",
       "              }\n",
       "            }\n",
       "        },\n",
       "       'brunelControls' : {\n",
       "            exports: 'BrunelEventHandlers',\n",
       "            init: function() {\n",
       "               return {\n",
       "                 BrunelEventHandlers: BrunelEventHandlers,\n",
       "                 BrunelJQueryControlFactory: BrunelJQueryControlFactory\n",
       "              }\n",
       "            }\n",
       "        }\n",
       "\n",
       "    }\n",
       "\n",
       "});\n",
       "\n",
       "require([\"d3\"], function(d3) {\n",
       "    require([\"brunel\", \"brunelControls\"], function(brunel, brunelControls) {\n",
       "        function  BrunelVis(visId) {\n",
       "  \"use strict\";                                                                       // strict mode\n",
       "  var datasets = [],                                      // array of datasets for the original data\n",
       "      pre = function(d, i) { return d },                         // default pre-process does nothing\n",
       "      post = function(d, i) { return d },                       // default post-process does nothing\n",
       "      transitionTime = 200,                                        // transition time for animations\n",
       "      charts = [],                                                       // the charts in the system\n",
       "      vis = d3.select('#' + visId).attr('class', 'brunel');                     // the SVG container\n",
       "\n",
       "  BrunelD3.addDefinitions(vis);                                   // ensure standard symbols present\n",
       "\n",
       "  // Define chart #1 in the visualization //////////////////////////////////////////////////////////\n",
       "\n",
       "  charts[0] = function(parentNode, filterRows) {\n",
       "    var geom = BrunelD3.geometry(parentNode || vis.node(), 0, 0, 1, 1, 0, 0, 0, 0),\n",
       "      elements = [];                                              // array of elements in this chart\n",
       "\n",
       "    // Define groups for the chart parts ///////////////////////////////////////////////////////////\n",
       "\n",
       "    var chart =  vis.append('g').attr('class', 'chart1')\n",
       "      .attr('transform','translate(' + geom.chart_left + ',' + geom.chart_top + ')');\n",
       "    var overlay = chart.append('g').attr('class', 'element').attr('class', 'overlay');\n",
       "    var zoom = d3.zoom().scaleExtent([1/3,3]);\n",
       "    var zoomNode = overlay.append('rect').attr('class', 'overlay')\n",
       "      .attr('x', geom.inner_left).attr('y', geom.inner_top)\n",
       "      .attr('width', geom.inner_rawWidth).attr('height', geom.inner_rawHeight)\n",
       "      .style('cursor', 'default')\n",
       "      .node();\n",
       "    zoomNode.__zoom = d3.zoomIdentity;\n",
       "    chart.append('rect').attr('class', 'background').attr('width', geom.chart_right-geom.chart_left).attr('height', geom.chart_bottom-geom.chart_top);\n",
       "    var interior = chart.append('g').attr('class', 'interior zoomNone')\n",
       "      .attr('transform','translate(' + geom.inner_left + ',' + geom.inner_top + ')')\n",
       "      .attr('clip-path', 'url(#clip_visid7722f3ba-370b-11e7-bcfb-002590fb6e1c_chart1_inner)');\n",
       "    interior.append('rect').attr('class', 'inner').attr('width', geom.inner_width).attr('height', geom.inner_height);\n",
       "    var gridGroup = interior.append('g').attr('class', 'grid');\n",
       "    vis.append('clipPath').attr('id', 'clip_visid7722f3ba-370b-11e7-bcfb-002590fb6e1c_chart1_inner').append('rect')\n",
       "      .attr('x', 0).attr('y', 0)\n",
       "      .attr('width', geom.inner_rawWidth+1).attr('height', geom.inner_rawHeight+1);\n",
       "    var scale_x = d3.scaleLinear(), scale_y = d3.scaleLinear();\n",
       "    var base_scales = [scale_x, scale_y];                           // untransformed original scales\n",
       "    zoom.on('zoom', function(t, time) {\n",
       "        t = t || d3.event.transform;\n",
       "        zoomNode.__zoom = t;\n",
       "        interior.attr('class', 'interior ' + BrunelD3.zoomLabel(t.k));;\n",
       "        interior.attr('transform', d3.zoomTransform(zoomNode));\n",
       "    });\n",
       "\n",
       "    // Define element #1 ///////////////////////////////////////////////////////////////////////////\n",
       "\n",
       "    elements[0] = function() {\n",
       "      var original, processed,                           // data sets passed in and then transformed\n",
       "        element, data,                                 // brunel element information and brunel data\n",
       "        selection, merged;                                      // d3 selection and merged selection\n",
       "      var elementGroup = interior.append('g').attr('class', 'element1')\n",
       "        .attr('transform','translate(' + geom.inner_width/2 + ',' + geom.inner_height/2 + ')'),\n",
       "        main = elementGroup.append('g').attr('class', 'main'),\n",
       "        labels = BrunelD3.undoTransform(elementGroup.append('g').attr('class', 'labels').attr('aria-hidden', 'true'), elementGroup);\n",
       "\n",
       "      function makeData() {\n",
       "        original = datasets[0];\n",
       "        if (filterRows) original = original.retainRows(filterRows);\n",
       "        processed = pre(original, 0);\n",
       "        processed = post(processed, 0);\n",
       "        var f0 = processed.field('Message'),\n",
       "          f1 = processed.field('#row'),\n",
       "          f2 = processed.field('#selection');\n",
       "        var keyFunc = function(d) { return f1.value(d) };\n",
       "        data = {\n",
       "          Message:      function(d) { return f0.value(d.row) },\n",
       "          $row:         function(d) { return f1.value(d.row) },\n",
       "          $selection:   function(d) { return f2.value(d.row) },\n",
       "          Message_f:    function(d) { return f0.valueFormatted(d.row) },\n",
       "          $row_f:       function(d) { return f1.valueFormatted(d.row) },\n",
       "          $selection_f: function(d) { return f2.valueFormatted(d.row) },\n",
       "          _split:       function(d) { return 'ALL' },\n",
       "          _key:         keyFunc,\n",
       "          _rows:        BrunelD3.makeRowsWithKeys(keyFunc, processed.rowCount())\n",
       "        };\n",
       "      }\n",
       "\n",
       "      // Build element from data ///////////////////////////////////////////////////////////////////\n",
       "\n",
       "      function build(transitionMillis) {\n",
       "        element = elements[0];\n",
       "        // Build the cloud layout\n",
       "        var cloud = BrunelD3.cloudLayout(processed, [geom.inner_width, geom.inner_height], zoomNode);\n",
       "        function keyFunction(d) { return d.key };\n",
       "        main.attr('class', 'diagram cloud');\n",
       "\n",
       "        // Define selection entry operations\n",
       "        function initialState(selection) {\n",
       "          selection\n",
       "            .attr('class', 'element text filled')\n",
       "            .style('text-anchor', 'middle').classed('label', true)\n",
       "            .text(function(d) { return data.Message_f(d) })\n",
       "            .style('pointer-events', 'none')\n",
       "        }\n",
       "\n",
       "        // Define selection update operations on merged data\n",
       "        function updateState(selection) {\n",
       "          selection\n",
       "            .each(cloud.prepare).call(cloud.build);\n",
       "        }\n",
       "        // Create selections, set the initial state and transition updates\n",
       "        selection = main.selectAll('.element').data(data._rows, function(d) { return d.key });\n",
       "        var added = selection.enter().append('text');\n",
       "        merged = selection.merge(added);\n",
       "        initialState(added);\n",
       "        selection.filter(BrunelD3.hasData)\n",
       "          .classed('selected', BrunelD3.isSelected(data))\n",
       "          .filter(BrunelD3.isSelected(data)).raise();\n",
       "        updateState(BrunelD3.transition(merged, transitionMillis));\n",
       "\n",
       "        BrunelD3.transition(selection.exit(), transitionMillis/3)\n",
       "          .style('opacity', 0.5).each( function() {\n",
       "            this.remove(); BrunelD3.removeLabels(this); \n",
       "        });\n",
       "      }\n",
       "\n",
       "      return {\n",
       "        data:           function() { return processed },\n",
       "        original:       function() { return original },\n",
       "        internal:       function() { return data },\n",
       "        selection:      function() { return merged },\n",
       "        makeData:       makeData,\n",
       "        build:          build,\n",
       "        chart:          function() { return charts[0] },\n",
       "        group:          function() { return elementGroup },\n",
       "        fields: {\n",
       "          key:          ['#row']\n",
       "        }\n",
       "      };\n",
       "    }();\n",
       "\n",
       "    function build(time, noData) {\n",
       "      var first = elements[0].data() == null;\n",
       "      if (first) time = 0;                                           // no transition for first call\n",
       "      if ((first || time > -1) && !noData) {\n",
       "        elements[0].makeData();\n",
       "      }\n",
       "      elements[0].build(time);\n",
       "    }\n",
       "\n",
       "    // Expose the following components of the chart\n",
       "    return {\n",
       "      elements : elements,\n",
       "      interior : interior,\n",
       "      zoom: function(params, time) {\n",
       "          if (params) zoom.on('zoom').call(zoomNode, params, time);\n",
       "          return d3.zoomTransform(zoomNode);\n",
       "      },\n",
       "      build : build\n",
       "    };\n",
       "    }();\n",
       "\n",
       "  function setData(rowData, i) { datasets[i||0] = BrunelD3.makeData(rowData) }\n",
       "  function updateAll(time) { charts.forEach(function(x) {x.build(time || 0)}) }\n",
       "  function buildAll() {\n",
       "    for (var i=0;i<arguments.length;i++) setData(arguments[i], i);\n",
       "    updateAll(transitionTime);\n",
       "  }\n",
       "\n",
       "  return {\n",
       "    dataPreProcess:     function(f) { if (f) pre = f; return pre },\n",
       "    dataPostProcess:    function(f) { if (f) post = f; return post },\n",
       "    data:               function(d,i) { if (d) setData(d,i); return datasets[i||0] },\n",
       "    visId:              visId,\n",
       "    build:              buildAll,\n",
       "    rebuild:            updateAll,\n",
       "    charts:             charts\n",
       "  }\n",
       "}\n",
       "\n",
       "// Data Tables /////////////////////////////////////////////////////////////////////////////////////\n",
       "\n",
       "var table1 = {\n",
       "   summarized: false,\n",
       "   names: ['Message'], \n",
       "   options: ['string'], \n",
       "   rows: [['Mercury'], ['Venus'], ['Earth'], ['Mars'], ['Jupiter'], ['Saturn'], ['Uranus'],\n",
       "  ['Neptune']]\n",
       "};\n",
       "\n",
       "// Call Code to Build the system ///////////////////////////////////////////////////////////////////\n",
       "\n",
       "var v  = new BrunelVis('visid7722f3ba-370b-11e7-bcfb-002590fb6e1c');\n",
       "v.build(table1);\n",
       "\n",
       "    });\n",
       "});"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import brunel\n",
    "\n",
    "%brunel cloud data('results_pd') label(Message) :: width=700, height=400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (Experimental) with Spark 1.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}